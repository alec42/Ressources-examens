% Template pour faire aide-mémoire
\documentclass[10pt, french]{article}

%% -----------------------------
%% Préambule
%% -----------------------------
\input{cheatsht-preamble-general.tex}
%% -----------------------------
%% Variable definition
%% -----------------------------
\def\cours{MAS-I}
\def\sigle{(CAS)}
%
% 	Save more space than default
%
\setlength{\abovedisplayskip}{-15pt}
\setlist{leftmargin=*}
\setcounter{secnumdepth}{0}
%
%	Extra math symbols
%
\usepackage{mathrsfs}
%
% 	thin space, limits underneath in displays
%
\DeclareMathOperator*{\argmax}{arg\,max} 

%% -----------------------------
%% 	Colour setup for sections
%% -----------------------------
\def\SectionColor{cobalt}
\def\SubSectionColor{azure(colorwheel)}
\def\SubSubSectionColor{azure(colorwheel)}
%% -----------------------------

%% -----------------------------
%% Color definitions
%% -----------------------------
\definecolor{indigo(web)}{rgb}{0.29, 0.0, 0.51}
\definecolor{cobalt}{rgb}{0.0, 0.28, 0.67}
\definecolor{azure(colorwheel)}{rgb}{0.0, 0.5, 1.0}
%% -----------------------------
%% Variable definition
%% -----------------------------
%%
%% Matrix notation variable (bold style)
%%
\newcommand\cololine[2]{\colorlet{temp}{.}\color{#1}\bar{\color{temp}#2}\color{temp}}
\newcommand\colbar[2]{\colorlet{temp}{.}\color{#1}\bar{\color{temp}#2}\color{temp}}
\usepackage{scalerel,stackengine,amsmath}
\newcommand\equalhat{\mathrel{\stackon[1.5pt]{=}{\stretchto{%
    \scalerel*[\widthof{=}]{\wedge}{\rule{1ex}{3ex}}}{0.5ex}}}}

\begin{document}

\begin{center}
	\textsc{\Large Contributeurs}\\[0.5cm] 
\end{center}
%\input{contributeurs/contrib-MAS-I}

\newpage
\raggedcolumns
\begin{multicols*}{2}

\paragraph{Note}	The moments of a mixture, are the mixture of the moments.

\def\SectionColor{red!80!white}
\section{Lesson 25: Estimator Quality}
\begin{distributions}[Sample Statistics]
\begin{description}
	\item[Sample Mean]	Unbiased estimator of the true mean $\mu$.
\begin{align*}
	\bar{x}
	&=	\frac{\sumz{n}{i = 1} x_{i}}{n}
\end{align*}
	\item[Sample Variance]	Unbiased estimator of the true variance $\sigma^{2}$.
\begin{align*}
	s^{2} 
	&=	\frac{\sum (x_{i} - \bar{x})^{2}}{n - 1}
\end{align*}
	\item[Empirical Variance]	Biased estimator of the true variance $\sigma^{2}$.
		\begin{align*}
		\hat{\sigma}^{2} 
		&=	\frac{\sum (x_{i} - \bar{x})^{2}}{n}
		\end{align*}
\end{description}
\end{distributions}

\section{Lesson 27: Method of Moments}
\begin{distributions}[Notation]
\begin{description}
	\item[$\mu_{k}'$]	$k^{\text{th}}$ moment centred around 0, \icbox{$\mu_{k}' = \text{E}[X^{k}]$}.
	\item[$\equalhat$]	Set equal.
\end{description}
\end{distributions}

\textbf{Exponential Distribution}
There is only one parameter $\theta$ which is the mean, we set \icbox[red][palechestnut]{$\hat{\theta}	\equalhat	\mu'_{1}$}.

\textbf{Gamma Distribution}
We have:
\begin{align*}
	\esp{X}
	&=	\alpha\theta	
	\equalhat	\bar{x}	&
	\text{Var}(X)
	&=	\alpha\theta^{2}
	\equalhat	\hat{\sigma}^{2}	\\
	\therefore
	\hat{\theta}
	&=	\frac{\hat{\sigma}^{2}}{\bar{x}}	
	=	\frac{\hat{\mu}_{2}' -  \hat{\mu}_{1}'^{2}}{\hat{\mu}_{1}'}	&
	\hat{\alpha}
	&=	\frac{\bar{x}^{2}}{\hat{\sigma}^{2}}
	=	\frac{\hat{\mu}_{1}'^{2}}{\hat{\mu}_{2}' -  \hat{\mu}_{1}'^{2}}
\end{align*}

\textbf{Pareto Distribution}
\begin{align*}
	\esp{X}
	&=	\frac{\theta	}{\alpha  -  1}
	\equalhat	\hat{\mu}_{1}'	&
	\esp{X^{2}}
	&=	\frac{2\theta^{2}}{(\alpha  -  1)(\alpha - 2)}
	\equalhat	\hat{\mu}_{2}'	\\
	\therefore
	\hat{\alpha}
	&=	\frac{2(\hat{\mu}_{2}' - \hat{\mu}_{1}'^{2})}{(\hat{\mu}_{2}' - 2\hat{\mu}_{1}'^{2})}	&
	\hat{\theta}
	&=	\frac{\hat{\mu}_{1}'\hat{\mu}_{2}'}{\hat{\mu}_{2}' - 2\hat{\mu}_{1}'^{2}}
\end{align*}

\textbf{Lognormal Distribution}
\begin{align*}
	\hat{\mu}
	&=	2\ln(\hat{\mu}_{1}') - 0.5\ln(\hat{\mu}_{2}')	&
	\hat{\sigma}^{2}
	&=	\ln(\hat{\mu}_{2}') - 2\ln(\hat{\mu}_{1}')	
\end{align*}

\textbf{Uniform Distribution}
\begin{align*}
	\esp{X}
	&=	\frac{\theta}{2}	&
	\therefore
	\hat{\theta}
	&=	2\hat{\mu}_{1}'
\end{align*}

\section{Lesson 28: Percentile Matching}
\paragraph*{Note:}	Exams don't typically ask a lot of percentile matching questions, thus it's not really worth memorizing each distribution's formulas as it can easily be about a random distribution.\\
\textbf{Exponential Distribution}
\begin{align*}
	\hat{\theta}
	&=	\frac{-\pi_{g}}{\ln(1 - g)}
\end{align*}

\textbf{Weibull Distribution}
\begin{align*}
	\hat{\tau}
	&=	\frac{\ln\left(\ln(1 - g_{1})/\ln(1 - g_{2})\right)}{\ln(\pi_{g_{1}}/\pi_{g_{2}})}	&
	\hat{\theta}
	&=	\frac{\pi_{g_{1}}}{\sqrt[\hat{\tau}]{-\ln(1 - g_{1})}}
\end{align*}

\textbf{Lognormal Distribution} (use the percentiles of a normal distribution $z_{p}$)
\begin{align*}
	\hat{\sigma}
	&=	\frac{\ln(\pi_{g_{2}}) - \ln(\pi_{g_{1}})}{z_{g_{2}} - z_{g_{1}}}	&
	\hat{\mu}
	&=	\ln(\pi_{g_{1}}) - z_{g_{1}} \hat{\sigma}
\end{align*}

\subsubsection*{Truncated data}
For $(X | X > d)$:
\begin{align*}
	F_{X}(x | X > d)
	&=	\frac{F_{X}(x) - F_{x}(d)}{S_{X}(d)}	&
	S_{X}(x | X > d) 
	&=	\frac{S_{X}(x)}{S_{X}(d)}
\end{align*}


\section{Lesson 29: }
\section{Lesson 30: MLE Special Techniques}
If the likelihood function is of the form \lfbox[formula]{$\mathcal{L}(\gamma)	=	\gamma^{-a}\textrm{e}^{-b/\gamma}$} then \lfbox[formula]{$\hat{\gamma}^{\text{MLE}}	=	\frac{b}{a}$}.

If the likelihood function is of the form \lfbox[formula]{$\mathcal{L}(\lambda)	=	\lambda^{a}\textrm{e}^{-\lambda b}$} then \lfbox[formula]{$\hat{\lambda}^{\text{MLE}}	=	\frac{a}{b}$}.

If the likelihood function is of the form \lfbox[formula]{$\mathcal{L}(\theta)	=	\theta^{a}(1	-	\theta)^{b}$} then \lfbox[formula]{$\hat{\theta}^{\text{MLE}}	=	\frac{a}{a + b}$}.

\textbf{Exponential}
\begin{align*}
	\hat{\theta}
	&=	\frac{\sumz{n + c}{i = 1}(x_{i}	-	d_{i})}{n}
\end{align*}

\textbf{Weibull} with a fixed $\tau$
\begin{align*}
	\hat{\theta}
	&=	\sqrt[\tau]{\frac{\sumz{n + c}{i	=	1}x_{i}^{\tau} - \sumz{n + c}{i	=	1}d_{i}^{\tau}}{n}}
\end{align*}

\textbf{Lognormal} (use the percentiles of a normal distribution $z_{p}$)
\begin{align*}
	\hat{\sigma}
	&=	\sqrt{\frac{\sumz{n}{i = 1}\ln^{2} x_{i}}{n} - \hat{\mu}^{2}}	&
	\hat{\mu}
	&=	\frac{\sumz{n}{i = 1}\ln x_{i}}{n}
\end{align*}

\textbf{Uniform $(0, \theta)$} for individual data
\begin{align*}
	\hat{\theta}
	&=	\max x_{i}
\end{align*}

\textbf{Uniform $(0, \theta)$} for grouped data
\begin{description}
	\item[$c_{j}$]	Upper bound of highest finite interval
	\item[$n_{j}$]	Number of observations below $c_{j}$
\end{description}
\begin{align*}
	\hat{\theta}
	&=	c_{j} \left(\frac{n}{n_{j}}\right)	\\
\end{align*}

\textbf{Inverse exponential}
\begin{align*}
	\hat{\theta}
	&=	\frac{n}{\sumz{n}{i = 1}(1/x_{i})}
\end{align*}

\textbf{Two-parameter Pareto}, fixed $\theta$
\begin{align*}
	\hat{\alpha}
	&=	-\frac{n}{K}	&
	K
	&=	\sumz{n + c}{i	=	1} \left\{\ln (\theta +  d_{i})	-	\ln (\theta + x_{i})\right\}
\end{align*}

\textbf{Single-parameter Pareto}, fixed $\theta$
\begin{align*}
	\hat{\alpha}
	&=	-\frac{n}{K}	&
	K
	&=	\sumz{n + c}{i	=	1} \left\{\ln \max(\theta, d_{i})	-	\ln x_{i}\right\}
\end{align*}

\textbf{Beta}, fixed $\theta$, $\beta	=	1$
\begin{align*}
	\hat{\alpha}
	&=	-\frac{n}{K}	&
	K
	&=	\sumz{n + c}{i	=	1} \left\{\ln (x_{i})\right\}	-	n\ln \theta
\end{align*}

\textbf{Beta}, fixed $\theta$, $\alpha	=	1$
\begin{align*}
	\hat{\beta}
	&=	-\frac{n}{K}	&
	K
	&=	\sumz{n + c}{i	=	1} \left\{\ln (\theta - x_{i})\right\}	-	n\ln \theta
\end{align*}

\section{Lesson 31: }

\pagebreak

\def\SectionColor{blue!80!white}
\section{Lesson 51: Time Series: Trend and Seasonality}
\begin{distributions}[Notation]
At time $t$,
\begin{description}
	\item[$\{x_{t}\}$]	Observed time series.
		\begin{itemize}
		\item	Formally, a time series of length $n$ is written as $\{x_{t}: t	=	1, 2, \dots, n\}	=	\{x_{1}, x_{2}, \dots, x_{n}\}$.
		\item	For simplicity, we write $x_{t}$.
		\end{itemize}
	\item[$m_{t}$]	Trend.
	\item[$s_{t}$]	Seasonal effect.
	\item[$z_{t}$]	Error term.
		\begin{itemize}
		\item	It is generally a sequence of correlated variables with mean zero.
		\end{itemize}
\end{description}
\end{distributions}

\begin{definitionNOHFILLsub}[Additive decomposition model]
\begin{align*}
	x_{t}
	&=	m_{t} + s_{t} + z_{t}
\end{align*}

\tcbline

Estimation of seasonal variation:
\begin{align*}
	\hat{s}_{t}
	&=	x_{t}	-	\hat{m}_{t}
\end{align*}
\end{definitionNOHFILLsub}

\begin{definitionNOHFILLsub}[Multiplicative model]
When the seasonal effect $s_{t}$ tends to increase as the trend $m_{t}$ increases (i.e., $s_{t} \propto m_{t}$):
\begin{align*}
	x_{t}
	&=	m_{t} \cdot s_{t} + z_{t}
\end{align*}

\tcbline

When the trend itself is multiplicative:
\begin{align*}
	x_{t}
	&=	m_{t} \cdot s_{t} \cdot z_{t}	\\
	&\text{or}	\\
	\textrm{ln}(x_{t})
	&=	\ln(m_{t}) + \ln(s_{t}) + \ln(z_{t})	\\
\end{align*}
\begin{itemize}
	\item	However, The logarithmic model must be used with caution;\\	
			If $z_{t}$ is normally distributed then $\ln(z_{t})$ is lognormally distributed and thus has a \textit{greater mean}.
\end{itemize}

\tcbline

Estimation of seasonal variation:\\
\begin{align*}
	\hat{s}_{t}
	&=	\frac{x_{t}}{\hat{m}_{t}}
\end{align*}
\end{definitionNOHFILLsub}

\begin{rappel_enhanced}[Calculating seasonal variation]
For example, we suppose monthly data.	\\
So, 
\begin{enumerate}
	\item	We average the seasonal variations $\hat{s}_{t}$ for each month. 
	\item	For an additive model, we then subtract from the respective month's seasonal variations these twelve averages.
	\item	For a multiplicative model, we then divide the respective month's seasonal variations by these twelve averages.
\end{enumerate}
This leads to an average seasonal variation of 0 for each month.
\end{rappel_enhanced}


Center moving average for monthly data:
\begin{align*}
	\hat{m}_{t}
	&=	\frac{0.5 m_{t - 6} + \sumz{t + 5}{i = t - 5} m_{i} + 0.5m_{t + 6}}{12}
\end{align*}
\end{multicols*}


\end{document}
