\chapter[Extended Linear Models]{Extended Linear Models (30\% à 50\%)}

\subsection{Information}

\begin{distributions}[Description]
Notes du descriptif principal:
\begin{itemize}
	\item	Include GLMs which are commonly used to construct classification plans;
	\item	OLS model is covered as one member of the exponential family;
	\item	\texttt{R} is useful to better visualise and conceptualise the material;
\end{itemize}
\tcbline
Notes de la sous-section:
\begin{itemize}
	\item	OLS treated as \textit{one} type of model that may be used when the dependant variable follows the Normal distribution and the observations are (iid) with a constant variance;
	\item	All models assume data is (iid) from the exponentional family;
	\item	Assume linear relationship between dependant and independant variables;
	\item	Assume variance is a function of the mean;
	\item	\textbf{VIF} formula found on p. 102 of James et al. and p. 101 of Dobson is used and not hte one on p. 101 of James and et al.;
		\begin{align*}
			\text{VIF}(b_{j})
			&=	\frac{1}{1 - R_{(j)}^{2}}
		\end{align*}
	\item	Questions may contain parameter tables and plots (of the type shown in texts) with which we should familiarise ourselves;
\end{itemize}
\end{distributions}

\begin{outcomes}[Learning objectives]
\begin{enumerate}
	\item	Understand the assumptions behind different forms of the Extended Linear Model and be able to select the appropriate model from list below:
	\begin{multicols*}{2}
		\begin{itemize}
		\item	OLS;
		\item	GLM;
		\item	ANOVA;
		\item	GAM;
		\item	Local Regression;
		\item	Lasso;
		\item	Ridge Regression;
		\item	Partial Least Squares;
		\item	PCA regression;
		\end{itemize}
	\end{multicols*}
	\begin{knowledge}[Knowledge Statements]
	\begin{enumerate}[label = \alph*.]
		\item	Understand the relationship between mean and variance by model family member for the exponential distribution;
		\item	Understand how to select the appropriate distribution function for the dependent variable and the implication for the appropriate model form;
		\item	Link functions (Identity, Log, Logit, Power, Inverse);
		\item	Characteristics of Exponential Family (Binomial, Normal, Exponential, Gamma, Poisson, Inverse Gaussian, Negative Binomial, and Tweedie);
		\item	Canonical Forms of link function and effect of non-canonical link function on bias;
		\item	Penalized Regression as implemented using the Lasso or Ridge Regression;
		\item	Understand concept of models within models for Generalized Additive Models (GAM);
		\item	Understand dimension reduction using Partial Least Squares (PLS) or Principal Components Regression (PCR);
	\end{enumerate}
	\end{knowledge}
\tcbline
	\item	Evaluate models developed using Extended Linear Model approach;
	\begin{knowledge}[Knowledge Statements]
	\begin{enumerate}[label = \alph*.]
		\item	Raw or studentized Residuals;
		\item	$R^{2}$;
		\item	Cook's Distance and outliers;
		\item	Influential points;
		\item	Leverage;
		\item	AIC and BIC penalized log likelihood measures;
		\item	Standardized / Studentized Residuals;
		\item	Deviance, Deviance Residuals and relationship to likelihood;
		\item	Pearson Residuals vs. Deviance residuals;
		\item	Scatter, QQ and Box Plots;
		\item	Type III Sequential Chi-Square test;
		\item	$T$-test and Wald test for significance of regression coefficients;
		\item	Prediction intervals for response variable;
		\item	MSE and standard error;
		\item	Calculation and validity of $F$ test to compare 2 models (under OLS);
		\item	Cross-Validation;
		\item	Test vs. Train Error;
		\item	Bootstrapping to test model validity;
		\item	Prediction vs. Forecast Error;
		\item	Overfitting;
		\item	Bias-Variance Tradeoff;
		\item	Evaluate collinearity using VIF;
		\item	Evaluate appropriateness of underlying assumptions including homoscedasticity and autocorrelation of residuals;
	\end{enumerate}
	\end{knowledge}
\tcbline
	\item	Understand the algorithms behind the numerical solutions for the different forms of the Extended Linear Model family to enable interpretation of output from the statistical software employed in modeling and to make appropriate modeling choices when selecting modeling options;
	\begin{knowledge}[Knowledge Statements]
	\begin{enumerate}[label = \alph*.]
		\item	Maximum Likelihood and OLS;
		\item	Fisher Scoring (iterative weighted least squares as implemented using the Information and Score functions from section B. 1);
		\item	Quasi-Likelihood and relationship to maximum likelihood;
		\item	Collinearity (Aliasing) and model stability; 
		\item	Hat matrix $\bm{H}$;
		\item	Design matrix $\bm{X}$;
		\item	Fitting adjoining, overlapping observations in groups for Local Regression;
		\item	Supervised vs. Unsupervised learning methods;
		\item	Modeling functions within functions for GAMs;
		\item	Penalty function in Penalized regression models (Lasso and Ridge Regression);
		\item	PLS supervised learning vs. PCR unsupervised learning;
	\end{enumerate}
	\end{knowledge}
\tcbline
	\item	Understand and be able to select the appropriate model structure for an Extended Linear Model given the behavior of the data set to be modeled;
	\begin{knowledge}[Knowledge Statements]
	\begin{enumerate}[label = \alph*.]
		\item	Predictor variables;
		\item	Response variables;
		\item	Regression through the origin;
		\item	Transformation of variables;
		\item	Categorical vs. continuous explanatory variables;
		\item	Interaction terms;
		\item	Significance and model comparison statistics;
		\item	Residuals and model parameter selection;
		\item	Piecewise linear and Smoothing Splines;
		\item	Smoothing parameter for splines;
		\item	Basis Functions;
		\item	Knot Selection for Splines;
		\item	Weighting function for local regression;
		\item	Selection of functions within functions for GAMs;
		\item	Selection of appropriate tuning factor for Lasso or Ridge Regression;
		\item	Select either Lasso or Ridge Regression depending on desired effect from penalized regression;
		\item	Curse of High Dimensionality;
		\item	Forward or backward or best subset selection;
	\end{enumerate}
	\end{knowledge}
\end{enumerate}
\end{outcomes}

\begin{ASM_chapter}[Related lessons ASM]
\begin{enumerate}
  \setcounter{enumi}{41}
	\item	\nameref{L.-42}
	\item	\nameref{L.-43}
	\item	\nameref{L.-44}
	\item	\nameref{L.-45}
	\item	\nameref{L.-46}
	\item	\nameref{L.-47}
	\item	\nameref{L.-48}
	\item	\nameref{L.-49}
	\item	\nameref{L.-50}
	\item	\nameref{L.-51}
	\item	\nameref{L.-52}
	\item	\nameref{L.-53}
	\item	\nameref{L.-54}
	\item	\nameref{L.-55}
	\item	\nameref{L.-56}
\end{enumerate}
\end{ASM_chapter}

\begin{YTB_vids}[Vidéos YouTube]
\begin{itemize}
	\item	
\end{itemize}
\end{YTB_vids}

\subsection{Résumés des chapitres}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-42}]{Introduction to Extended Linear Models}
Introduction to Mathematical Statistics 4.4
Introduction to Generalized Linear Models 2
Introduction to Statistical Learning with R 2 (except 2.2.3)
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-43}]{How a Generalized Linear Model Works}
Introduction to Generalized Linear Models 3.9
Introduction to Statistical Learning with R 3.3.1 - 3.3.2
Larsen Study Note
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-44}]{How a Generalized Linear Model Works: Categorical Response}
Introduction to Generalized Linear Models 7, 8
Introduction to Statistical Learning with R 4
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-45}]{Generalized Linear Model: Estimating Parameters}
Introduction to Generalized Linear Models 4
Introduction to Statistical Learning with R 3.1.1, 3.2.1
Larsen Study Note
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-46}]{Generalized Linear Model: Measures of Fit}
Introduction to Generalized Linear Models 5
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-47}]{{Normal Linear Model: Standard Error, $R$-squared, and $t$-statistic}}
Introduction to Generalized Linear Models 6.1 - 6.3
Introduction to Statistical Learning with R 3.1.2 - 3.1.3, 3.2.2 - 3.2.3
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-48}]{Normal Linear Model: $F$ and VIF}
Introduction to Generalized Linear Models 6.2
Introduction to Statistical Learning with R 3
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-49}]{Normal Linear Model: Validation}
Introduction to Generalized Linear Models 6.2
Introduction to Statistical Learning with R 3.3.3
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-50}]{Normal Linear Model: Predictions}
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-51}]{ANOVA}
Introduction to Generalized Linear Models 6.4 - 6.5, 9.3 - 9.7
Introduction to Mathematical Statistics 9.1 - 9.5
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-52}]{Generalized Linear Model: Measures of Fit II}
Introduction to Generalized Linear Models 7, 8, 9
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-53}]{Resampling Methods}
Introduction to Statistical Learning with R 5
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-54}]{Normal Linear Model: Subset Selection}
Introduction to Statistical Learning with R 6.1
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-55}]{Normal Linear Model: Shrinkage and Dimension Reduction}
Introduction to Statistical Learning with R 6.2 - 6.4
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-56}]{Extensions to the Linear Model}
Introduction to Statistical Learning with R 7
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\subsection{Notes sur les vidéos YouTube}

\begin{YTB_SUMM}[label = {SQ-BASICS-ML-INTRO}]{\href{https://www.youtube.com/watch?v=Gv9_4yMHFhI&list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&index=2&t=0s}{StatQuest: A Gentle Introduction to Machine Learning}}
\begin{itemize}
	\item	
\end{itemize}
\end{YTB_SUMM}