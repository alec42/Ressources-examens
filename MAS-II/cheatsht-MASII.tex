\documentclass[english]{article}
%% -----------------------------
%% PrÃ©ambule
%% -----------------------------
\input{../cheatsht-preamble-general-en.tex}

%% -----------------------------
%% Variable definition
%% -----------------------------
\def\cours{Modern Actuarial Statistics II}
\def\sigle{MAS-II}

%
% 	Save more space than default
%
\setlength{\abovedisplayskip}{-15pt}
\setlist{leftmargin=*}

%% -----------------------------
%% 	Colour setup for sections
%% -----------------------------
\def\SectionColor{cobalt}
\def\SubSectionColor{azure(colorwheel)}
\def\SubSubSectionColor{azure(colorwheel)}
%%%	depth
\setcounter{secnumdepth}{0}
%% -----------------------------

%% -----------------------------
%% 	Format part
%% -----------------------------
\titleformat
	{\part}			%	command
	[display]		%	shape
	{\normalfont\bfseries\filcenter}	%	format
	{\LARGE\thepart}	%	label
	{1ex}			%	sep
	{
		\titlerule[2pt]
		\vspace{2ex}%
		\LARGE
	}				%	before-code
	[
		\vspace{1ex}%
		{\titlerule[2pt]}
	]				%	after-code
\titlespacing{\part}
	{0pc}			%	left margin spacing
	{-5mm}			%	vertical space before title
	{1pc}			%	seperation between title and non-sectioning text
\renewcommand\thepart{\Alph{part}}
%% -----------------------------

%% -----------------------------
%% Color definitions
%% -----------------------------
\definecolor{indigo(web)}{rgb}{0.29, 0.0, 0.51}
\definecolor{cobalt}{rgb}{0.0, 0.28, 0.67}
\definecolor{azure(colorwheel)}{rgb}{0.0, 0.5, 1.0}
%% -----------------------------

%% -----------------------------
%% Variable definition
%% -----------------------------
%%
%% Matrix notation variable (bold style)
%%
\newcommand\cololine[2]{\colorlet{temp}{.}\color{#1}\bar{\color{temp}#2}\color{temp}}
\newcommand\colbar[2]{\colorlet{temp}{.}\color{#1}\bar{\color{temp}#2}\color{temp}}
\newcommand\cumlaut[2][black]{\stackon[.33ex]{#2}{\textcolor{#1}{\kern-.04ex.\kern-.2ex.}}}

%% -----------------------------
%% Tabular spacing
%% -----------------------------
%%
\newcommand\Tstrut{\rule{0pt}{2.6ex}}         % = `top' strut
\newcommand\Bstrut{\rule[-0.9ex]{0pt}{0pt}}   % = `bottom' strut


\begin{document}

\begin{center}
	\textsc{\Large Contributeurs}\\[0.5cm] 
\end{center}
\input{../contributeurs/contrib-MASII}

%\begin{rappel_enhanced}[Motivation]
%
%\end{rappel_enhanced}



\newpage
\raggedcolumns
\begin{multicols*}{2}
\tableofcontents


\newpage
\part{Prerequisites}\label{part:prereq}
\section{Distributions}\label{sec:0Distributions}
\begin{rappel_enhanced}[Context]
We typically use 3 types of random variable to describe losses:

\begin{center}
\begin{tabular}{| >{\columncolor{beaublue}}m{6cm} | >{\columncolor{beaublue}}m{3cm}  |}
\hline
\hyperlink{0discrDistr}{\color{bleudefrance} Frequency} or number of losses	&	always discrete	\\\hline
\hyperlink{0sevDistr}{\color{bleudefrance} Severity} or amount of losses (payment)	&	usually continuous, can be discrete or mixed too	\\\hline
\hyperlink{0aggDistr}{\color{bleudefrance} Aggregate} or total loss from summing a number (Frequency) of Severity variables	&	same as the severity	\\\hline
\end{tabular}
\end{center}
\end{rappel_enhanced}

\subsection{Discrete Distributions}\label{subsec:0discrDistr}
\begin{rappel_enhanced}[Context]
Discrete random variables are usually counting (frequency) variables, meaning their possible values are $\{0, 1, 2, \dots\}$
\end{rappel_enhanced}

\begin{definitionNOHFILL}[\hypertarget{0pmf}{Probability Mass Function (PMF)}]
$N$ is a \textit{discrete random variable} if it has a \textbf{\textit{probability mass function}} $p_{k}$ such that \lfbox[formula]{$p_{k} = \Pr(N = k)$}
\begin{center}
\begin{tabular}{| >{\columncolor{beaublue}}c | >{\columncolor{beaublue}}c  | >{\columncolor{beaublue}}c  |}
\hline\rowcolor{airforceblue} 
\textcolor{white}{\textbf{Definition}}	&	\textcolor{white}{\textbf{Domain}}		&	\textcolor{white}{\textbf{Condition}}	\\\specialrule{0.1em}{0em}{0em} 
$p_{k} = \Pr(N = k)$	&	$p_{k} \in [0, 1]$	&	$\sum_{k} p_{k} = 1$\Tstrut\\\hline
\end{tabular}
\end{center}
\end{definitionNOHFILL}

\begin{definitionNOHFILLprop}[\hypertarget{0poissDistr}{Poisson Distribution}]
\begin{center}
\begin{tabular}{| >{\columncolor{beaublue}}c | >{\columncolor{beaublue}}c  | >{\columncolor{beaublue}}c  |}
\hline\rowcolor{airforceblue} 
\textcolor{white}{\textbf{Notation}}	&	\textcolor{white}{\textbf{Parameters}}		&	\textcolor{white}{\textbf{Domain}}	\\\specialrule{0.1em}{0em}{0em}
$N \sim \text{Poisson}(\lambda)$	&	$\lambda	>	0$	&	$n = 0, 1, 2, \dots$	\\\hline
\end{tabular}
\end{center}


\begin{center}
\begin{tabular}{| >{\columncolor{airforceblue}}m{2cm} | >{\columncolor{beaublue}}m{4cm}  |}
\specialrule{0.1em}{0em}{0em}
\textcolor{white}{$\Pr(N = n)$}	&	 \[=\frac{\textrm{e}^{-\lambda} \lambda^{n}}{n!}\]		\\\specialrule{0.1em}{0em}{0em}
\textcolor{white}{$E[N]$}	&	 \[=\lambda\]		\\\specialrule{0.1em}{0em}{0em}
\textcolor{white}{$Var(N)$}	&	 \[=\lambda\]		\\\specialrule{0.1em}{0em}{0em}
\end{tabular}
\end{center}

\begin{itemize}
	\item	If $N_{1}$ and $N_{2}$ are \textit{independent} Poisson r.v., then $N_{1} + N_{2} \sim \text{Poisson}(\lambda_{1} + \lambda_{2})$.
	\item	The $\textrm{e}^{-\lambda}$ term makes the probabilities sum to $1$ as the Taylor series for $\textrm{e}^{\lambda}$ is $$\textrm{e}^{\lambda} = 1 + \lambda + \frac{\lambda^{2}}{2!} + \cdots + \frac{\lambda^{n}}{n!} + \cdots$$
\end{itemize}
\end{definitionNOHFILLprop}

\begin{definitionNOHFILLprop}[\hypertarget{0binDistr}{Binomial Distribution}]
\begin{rappel_enhanced}[Context]
A binomial r.v. $N$ has $m$ \textit{independent} trials each having a probability $q$ of a loss where $n$ is the total number of losses.
\end{rappel_enhanced}

\begin{center}
\begin{tabular}{| >{\columncolor{beaublue}}c | >{\columncolor{beaublue}}c  | >{\columncolor{beaublue}}c  |}
\hline\rowcolor{airforceblue} 
\textcolor{white}{\textbf{Notation}}	&	\textcolor{white}{\textbf{Parameters}}		&	\textcolor{white}{\textbf{Domain}}	\\\specialrule{0.1em}{0em}{0em}
$N \sim \text{Bin}(m, q)$	&	$q \in (0, 1); m \in \mathbb{N}$	&	$n = 0, 1, 2, \dots$	\\\hline
\end{tabular}
\end{center}


\begin{center}
\begin{tabular}{| >{\columncolor{airforceblue}}m{2cm} | >{\columncolor{beaublue}}m{4cm}  |}
\specialrule{0.1em}{0em}{0em}
\textcolor{white}{$\Pr(N = n)$}	&	 \[= \binom{m}{n} q^{n} (1 - q)^{m - n} \]		\\\specialrule{0.1em}{0em}{0em}
\textcolor{white}{$E[N]$}	&	 \[= mq \]		\\\specialrule{0.1em}{0em}{0em}
\textcolor{white}{$Var(N)$}	&	 \[= mq \]		\\\specialrule{0.1em}{0em}{0em}
\end{tabular}
\end{center}

\begin{itemize}
	\item	If $N_{1}$ and $N_{2}$ are \textit{independent} binomial r.v. with the \textbf{\textit{same}} $q$ then $N_{1} + N_{2} \sim \text{Bin}(m_{1} + m_{2}, q)$.
	\item	The case where $m = 1$ corresponds to a \textit{\textbf{Bernoulli}} r.v.
\end{itemize}
\end{definitionNOHFILLprop}

\begin{definitionNOHFILLprop}[\hypertarget{0geoDistr}{Geometric Distribution}]
\begin{rappel_enhanced}[Context]
A geometric r.v. $N$ with mean $\beta$ can be obtained by setting $n$ as the number of years \textit{\textbf{before}} the \underline{first} loss. Given the geometric distribution is memoryless, each year \textit{independently} has a loss with probability $\displaystyle \underbrace{\Pr(N = 0)}_{\shortstack{probability of a\\ loss the first year}} = \frac{1}{1 + \beta}$.	
\end{rappel_enhanced}

\begin{center}
\begin{tabular}{| >{\columncolor{beaublue}}c | >{\columncolor{beaublue}}c  | >{\columncolor{beaublue}}c  |}
\hline\rowcolor{airforceblue} 
\textcolor{white}{\textbf{Notation}}	&	\textcolor{white}{\textbf{Parameters}}		&	\textcolor{white}{\textbf{Domain}}	\\\specialrule{0.1em}{0em}{0em}
$N \sim \text{Geo}(\beta)$	&	$\beta > 0$	&	$n = 0, 1, 2, \dots$	\\\hline
\end{tabular}
\end{center}


\begin{center}
\begin{tabular}{| >{\columncolor{airforceblue}}m{2cm} | >{\columncolor{beaublue}}m{4cm}  |}
\specialrule{0.1em}{0em}{0em}
\textcolor{white}{$\Pr(N = n)$}	&	 \[=\left(\frac{\beta}{1 + \beta}\right)^{n} \frac{1}{1 + \beta}	\]		\\\specialrule{0.1em}{0em}{0em}
\textcolor{white}{$\Pr(N \geq n)$}	&	 \[=\left(\frac{\beta}{1 + \beta}\right)^{n}	\]		\\\specialrule{0.1em}{0em}{0em}
\textcolor{white}{$E[N]$}	&	 \[=\beta\]		\\\specialrule{0.1em}{0em}{0em}
\textcolor{white}{$Var(N)$}	&	 \[=\beta(1 + \beta)\]		\\\specialrule{0.1em}{0em}{0em}
\end{tabular}
\end{center}

\begin{itemize}
	\item	Like the \hyperlink{0expDist}{\color{bleudefrance} exponential distribution}, the geometric distribution is memoryless:
		\begin{align*}
		\Pr(N = d + n | N \geq d)
		&=	\Pr(N = n)	\\
		E[N - d | N \geq d]
		&=	E[N]
		\end{align*}
\end{itemize}
\end{definitionNOHFILLprop}

\begin{definitionNOHFILLprop}[Negative Binomial Distribution]
\begin{rappel_enhanced}[Context]
A negative binomial r.v. $N$ represents the number of years $n$ with no loss \textit{before} the $r^{\text{th}}$ year with a loss. We obtain a negative binomial r.v. $N \sim \text{NBin}(r, \beta)$ by summing $r$ iid geometric r.v., $N_{1}, N_{2}, \dots, N_{r}$, all with the same mean $\beta$.
\end{rappel_enhanced}

\begin{center}
\begin{tabular}{| >{\columncolor{beaublue}}c | >{\columncolor{beaublue}}c  | >{\columncolor{beaublue}}c  |}
\hline\rowcolor{airforceblue} 
\textcolor{white}{\textbf{Notation}}	&	\textcolor{white}{\textbf{Parameters}}		&	\textcolor{white}{\textbf{Domain}}	\\\specialrule{0.1em}{0em}{0em}
$N \sim \text{NBin}(\beta)$	&	$r, \beta > 0$	&	$n = 0, 1, 2, \dots$	\\\hline
\end{tabular}
\end{center}


\begin{center}
\begin{tabular}{| >{\columncolor{airforceblue}}m{2cm} | >{\columncolor{beaublue}}m{4cm}  |}
\specialrule{0.1em}{0em}{0em}
\textcolor{white}{$\Pr(N = n)$}	&	 \[= \binom{r + n - 1}{r - 1} \left(\frac{\beta}{1 + \beta}\right)^{n} \left(\frac{1}{1 + \beta}\right)^{r}	\]		\\\specialrule{0.1em}{0em}{0em}
\textcolor{white}{$\Pr(N \geq n)$}	&	 \[=\left(\frac{\beta}{1 + \beta}\right)^{n}	\]		\\\specialrule{0.1em}{0em}{0em}
\textcolor{white}{$E[N]$}	&	 \[=r\beta\]		\\\specialrule{0.1em}{0em}{0em}
\textcolor{white}{$Var(N)$}	&	 \[=r\beta(1 + \beta)\]		\\\specialrule{0.1em}{0em}{0em}
\end{tabular}
\end{center}

\begin{itemize}
	\item	A \hyperlink{0geoDistr}{\color{bleudefrance} geometric} r.v. is a negative binomial r.v. with $r = 1$.
\end{itemize}
\end{definitionNOHFILLprop}



\begin{center}
\begin{tabular}{| >{\columncolor{beaublue}}c | >{\columncolor{beaublue}}c   >{\columncolor{beaublue}}c  >{\columncolor{beaublue}}c  |}
\hline\rowcolor{airforceblue}
\textcolor{white}{\textbf{Distribution}}	&	\textcolor{white}{\textbf{Mean}}		&		&	\textcolor{white}{\textbf{Variance}}	\\\specialrule{0.1em}{0em}{0em}
Binomial				&	$mq$			&	$>$	&	$mq(1 - q)$			\\\hline
Poisson				&	$\lambda$	&	$=$	&	$\lambda$			\\\hline
Geometric			&	$\beta$		&	$<$	&	$\beta(1 + \beta)$	\\\hline
Negative Binomial	&	$r\beta$		&	$<$	&	$r\beta(1 + \beta)$	\\\hline
\end{tabular}
\end{center}



\subsection{Severity Distributions}\label{subsec:0sevDistr}

%\begin{definitionNOHFILL}[\hypertarget{0pdf}{Probability Density Function (PDF)}]
%$X$ is a \textit{continuous random variable} if it has a \textbf{\textit{probability density function}} $f(x)$ such that \lfbox[formula]{$f(x)$}
%\begin{center}
%\begin{tabular}{| >{\columncolor{beaublue}}c | >{\columncolor{beaublue}}c  | >{\columncolor{beaublue}}c  |}
%\hline\rowcolor{airforceblue} 
%\textcolor{white}{\textbf{Definition}}	&	\textcolor{white}{\textbf{Domain}}		&	\textcolor{white}{\textbf{Condition}}	\\\specialrule{0.1em}{0em}{0em} 
%$f(x) = $	&	$f(x) \geq 0$	&	$\int_{\mathbb{R}} f(x)dx = 1$\Tstrut\\\hline
%\end{tabular}
%\end{center}
%\end{definitionNOHFILL}

\subsection{Joint Distributions}\label{subsec:0jointDistr}
\subsection{Conditional Distributions}\label{subsec:0condDistr}
\subsection{Aggregate Distributions}\label{subsec:0aggDistr}
\subsection{Normal, Uniform, Pareto, Exponential, and Gamma}\label{subsec:0gaExpNoDistr}
%\begin{definitionNOHFILLprop}[Normal Distribution]
%\begin{rappel_enhanced}[Contexte]
%La distribution Pareto est un mÃ©lange de deux distributions exponentielles originalement conÃ§ue pour Ã©tudier des distributions de revenus. 
%\end{rappel_enhanced}
%
%\begin{center}
%\begin{tabular}{| >{\columncolor{beaublue}}c | >{\columncolor{beaublue}}c  | >{\columncolor{beaublue}}c  |}
%\hline\rowcolor{airforceblue} 
%\textcolor{white}{\textbf{Notation}}	&	\textcolor{white}{\textbf{Parameters}}		&	\textcolor{white}{\textbf{Domain}}	\\\specialrule{0.1em}{0em}{0em} 
%$X \sim \text{Pareto}(\alpha, \theta)$	&	$\alpha, \theta	>	0$	&	$x \geq 0$	\\\hline
%\end{tabular}
%\end{center}
%
%\begin{center}
%\begin{tabular}{| >{\columncolor{airforceblue}}m{1cm} | >{\columncolor{beaublue}}m{4cm}  |}
%\specialrule{0.1em}{0em}{0em}
%\textcolor{white}{$f(x)$}	&	 \[=	\frac{\alpha\theta^{\alpha}}{(x + \theta)^{\alpha + 1}}\]		\\\specialrule{0.1em}{0em}{0em}
%\textcolor{white}{$F(x)$}	&	 \[=1 -	\left(\frac{\theta}{x + \theta}\right)^{\alpha}\]		\\\specialrule{0.1em}{0em}{0em}
%\end{tabular}
%\end{center}
%
%\begin{itemize}
%	\item	Si $X \sim \text{Pareto}(\alpha, \theta)$ alors \lfbox[formula]{$Y	=	(X	-	d	|	X	>	d)	\sim \text{Pareto}(\alpha, \theta + d)$}.
%\end{itemize}
%\end{definitionNOHFILLprop}
%
%
%\begin{definitionNOHFILLprop}[Uniform Distribution]
%\begin{center}
%\begin{tabular}{| >{\columncolor{beaublue}}c | >{\columncolor{beaublue}}c  | >{\columncolor{beaublue}}c  |}
%\hline\rowcolor{airforceblue} 
%\textcolor{white}{\textbf{Notation}}	&	\textcolor{white}{\textbf{Parameters}}		&	\textcolor{white}{\textbf{Domain}}	\\\specialrule{0.1em}{0em}{0em} 
%$X \sim \text{Beta}(a, b, \theta)$	&	$a, b	>	0 \text{ et } \theta \geq 0$	&	$x \in [0, \theta]$	\\\hline
%\end{tabular}
%\end{center}
%
%\begin{center}
%\begin{tabular}{| >{\columncolor{airforceblue}}m{1cm} | >{\columncolor{beaublue}}m{4cm}  |}
%\specialrule{0.1em}{0em}{0em}
%\textcolor{white}{$f(x)$}	&	 \[= \frac{\theta}{\text{B}(a, b)}	\bigg(\frac{x}{\theta}\bigg)^{a - 1} \bigg(1 - \frac{x}{\theta}\bigg)^{b - 1}\]		\\\specialrule{0.1em}{0em}{0em}
%\end{tabular}
%\end{center}
%
%\begin{itemize}
%	\item	$X	\sim \text{Beta}(a = 1, b = 1, \theta) \sim \text{Unif}(0, \theta)$.
%	\item	Si $X \sim \text{Unif}(a, b)$ alors  \lfbox[formula]{$(X	|	X	>	d)	\sim \text{Unif}(d, b)$} et \lfbox[formula]{$(X	-	d	|	X	>	d)	\sim \text{Unif}(0, b - d)$}.
%\end{itemize}
%\end{definitionNOHFILLprop}
%
%
%\begin{definitionNOHFILLprop}[Pareto Distribution]
%\begin{rappel_enhanced}[Contexte]
%La distribution Pareto est un mÃ©lange de deux distributions exponentielles originalement conÃ§ue pour Ã©tudier des distributions de revenus. 
%\end{rappel_enhanced}
%
%\begin{center}
%\begin{tabular}{| >{\columncolor{beaublue}}c | >{\columncolor{beaublue}}c  | >{\columncolor{beaublue}}c  |}
%\hline\rowcolor{airforceblue} 
%\textcolor{white}{\textbf{Notation}}	&	\textcolor{white}{\textbf{Parameters}}		&	\textcolor{white}{\textbf{Domain}}	\\\specialrule{0.1em}{0em}{0em} 
%$X \sim \text{Pareto}(\alpha, \theta)$	&	$\alpha, \theta	>	0$	&	$x \geq 0$	\\\hline
%\end{tabular}
%\end{center}
%
%\begin{center}
%\begin{tabular}{| >{\columncolor{airforceblue}}m{1cm} | >{\columncolor{beaublue}}m{4cm}  |}
%\specialrule{0.1em}{0em}{0em}
%\textcolor{white}{$f(x)$}	&	 \[=	\frac{\alpha\theta^{\alpha}}{(x + \theta)^{\alpha + 1}}\]		\\\specialrule{0.1em}{0em}{0em}
%\textcolor{white}{$F(x)$}	&	 \[=1 -	\left(\frac{\theta}{x + \theta}\right)^{\alpha}\]		\\\specialrule{0.1em}{0em}{0em}
%\end{tabular}
%\end{center}
%
%\begin{itemize}
%	\item	Si $X \sim \text{Pareto}(\alpha, \theta)$ alors \lfbox[formula]{$Y	=	(X	-	d	|	X	>	d)	\sim \text{Pareto}(\alpha, \theta + d)$}.
%\end{itemize}
%\end{definitionNOHFILLprop}
%
%\hypertarget{0expDist}{Exponential Distribution}
%
%\begin{definitionNOHFILLprop}[Gamma Distribution]
%\begin{center}
%\begin{tabular}{| >{\columncolor{beaublue}}c | >{\columncolor{beaublue}}c  | >{\columncolor{beaublue}}c  |}
%\hline\rowcolor{airforceblue} 
%\textcolor{white}{\textbf{Notation}}	&	\textcolor{white}{\textbf{Parameters}}		&	\textcolor{white}{\textbf{Domain}}	\\\specialrule{0.1em}{0em}{0em} 
%$X \sim \text{Gamma}(\alpha, \theta)$	&	$\alpha, \theta > 0$	&	$x \geq	0$	\\\hline
%\end{tabular}
%\end{center}
%
%\begin{center}
%\begin{tabular}{| >{\columncolor{airforceblue}}m{1cm} | >{\columncolor{beaublue}}m{4cm}  |}
%\specialrule{0.1em}{0em}{0em}
%\textcolor{white}{$f(x)$}	&	 \[= \frac{x^{\alpha - 1} \textrm{e}^{-x/\theta}}{\Gamma(\alpha)\theta^{\alpha}}\]		\\\specialrule{0.1em}{0em}{0em}
%\end{tabular}
%\end{center}
%
%\begin{itemize}
%	\item	On appelle $\theta$ la moyenne et $\lambda	=	\frac{1}{\theta}$ le paramÃ¨tre de frÃ©quence (" \textit{rate} ").
%	\item	Soit n v.a. indÃ©pendantes \lfbox[conditions]{$X_{i}	\sim \text{Gamma}(\alpha_{i}, \theta)$} alors \lfbox[formula]{$\sum_{i = 1}^{n} X_{i} \sim \text{Gamma}(\sum_{i = 1}^{n} \alpha_{i}, \theta)$}.
%	\item	Soit n v.a. indÃ©pendantes \lfbox[conditions]{$X_{i}	\sim \text{Exp}(\lambda_{i})$} alors \lfbox[formula]{$Y	=	\min(X_{1}, \dots, X_{n})	\sim	\text{Exp}(\frac{1}{\sum_{i = 1}^{n} \lambda_{i})}$}.
%	\item	Si $X \sim \text{Exp}(\theta)$ alors \lfbox[formula]{$(X	-	d	|	X	>	d)	\sim \text{Exp}(\theta)$}.
%\end{itemize}
%\end{definitionNOHFILLprop}

\lfbox[formula]{$\gamma(1/2) = \sqrt{\pi}$}

\section{Statistics}
\begin{definitionNOHFILL}[Mode]
\begin{rappel_enhanced}[Context]
The mode is the value that occurs the most often. A non-mathematical example of the concept is looking at the most used letter in the English alphabet. The letter E is the most used letter in the dictionary and as such is the mode of the English language.
\end{rappel_enhanced}

In mathematical terms, the mode is the point which maximises the \hyperlink{0pmf}{\color{bleudefrance} PMF}/\hyperlink{0pdf}{\color{bleudefrance} PDF}.

\bigskip

Finding the mode of a continuous r.v. can be done by calculating the derivative of the PDF and finding the point where it equals $0$.  If the distribution is
\begin{itemize}
	\item	\textbf{unimodal}, i.e. it has a hump, then \lfbox[formula]{$\text{mode} = x \text{s.t.} f'(x) = 0$}.
	\item	\underline{strictly increasing} or \underline{decreasing}, the mode will be one of the 2 extremes.
		\begin{itemize}
		\item	For example, the exponential distribution is strictly decreasing and its mode is always $0$.
		\end{itemize}
\end{itemize}

\bigskip

For discrete variables, there are some ways to simplify it's calculation:
\begin{itemize}
	\item	Using the table function on the calculator and seeing where the probabilities peak.
	\item	Using the algebraic approach of looking at $p_{k} / p_{k - 1}$.
		\begin{itemize}
		\item	$p_{k} > p_{k - 1}$ iff $p_{k}/p_{k - 1} > 1$.
		\item	The mode is the largest $k$ s.t. $p_{k} > p_{k - 1}$.
		\end{itemize}
\end{itemize}

\paragraph{Note}	In the exam, it's best to use the calculator approach.
\end{definitionNOHFILL}


\newpage
\part{Introduction to Credibility}\label{part:cred}
\section{Basic Framework of Credibility}\label{sec:credBasics}
\begin{rappel_enhanced}[Context]
The \textbf{\textit{limitation fluctuation credibility}} approach, or \textbf{\textit{classical credibility}} approach, calculates an updated prediction ($U$) of the \textbf{loss measure} as a weighted ($Z$) average of recent claim experience ($D$) and a rate ($M$) specified in the manual. Thus, we calculate the \textit{premium} paid by the \textit{risk group} as \lfbox[formula]{$U = ZD + (1 - Z)M$}.
\end{rappel_enhanced}

\begin{distributions}[Notation]
\begin{description}
	\item[$M$]	Predicted loss based on the "\textit{\textbf{m}anual}".
	\item[$D$]	Observe\textbf{d} losses based on the recent experience of the risk group.
	\item[$Z$]	Weight assigned to the recent experience $D$ called the \textbf{\textit{credibility factor}} with \lfbox[conditions]{$Z \in [0, 1]$}. 
	\item[$U$]	\textbf{U}pdated prediction of the premium.
\end{description}
\end{distributions}

\begin{distributions}[Terminology]
\begin{description}
	\item[Risk group]	block of insurance policies, covered for a period of time upon payment of a \textit{premium}.
	\item[Claim frequency]	The number of claims denoted $N$.
	\item[Claim severity]	The amount of the $i^{\text{th}}$ claim denoted $X_{i}$.
	\item[Aggregate loss]	The total loss denoted $S$ where $S = X_{1} + X_{2} + \hdots + X_{N}$.
	\item[Pure premium]	The pure premium denoted $P$ where $P = S/E$ with $E$ denoting the number of exposure units.
\end{description}
\end{distributions}

\begin{definitionGENERAL}{Exam tips}[][ao(english)]
Typical questions about this involve being given 3 of $M, D, Z, \text{ and } U$ then finding the missing one.
\end{definitionGENERAL}


\begin{rappel_enhanced}[Context]
With $\min\{D, M\} \leq U \leq \max\{D, M\}$, we can see that the credibility factor determines the relative importance of the claim experience of the risk group $D$ relative to the manual rate $M$.

\bigskip

If $Z = 1$, we obtain \textit{\underline{\nameref{subsec:FullCred}}} where the predicted premium depends only on the data ($U = D$). It follows that with $Z < 1$, we obtain \textit{\underline{\nameref{subsec:PartialCred}}} as the weighted average of both $D$ and $M$.
\end{rappel_enhanced}


%\columnbreak
\subsection{Full Credibility}\label{subsec:FullCred}
\begin{rappel_enhanced}[Contexte]
The classical credibility approach determines the \textit{\textbf{minimum} data size} required for the experience data ($D$) to be given \textbf{\textit{full credibility}}. The minimum data size, or \textit{\textbf{standard for full credibility}}, depends on the \textbf{loss measure}.
\end{rappel_enhanced}


\subsubsection{Claim Frequency}
The claim frequency random variable $N$ has mean $\mu_{N}$ and variance $\sigma^{2}_{N}$. 

If we assume $N \approx \mathcal{N}(\mu_{N}, \sigma^{2}_{N})$, then the probability of observing claim frequency \textbf{within $k$ of the mean} is \lfbox[formula]{$\Pr(\mu_{N} - k\mu_{N} \leq N \leq \mu_{N} + k\mu_{N}) = 2 \Phi\left(\frac{k \mu_{N}}{\sigma_{N}}\right) - 1$}.

\bigskip

We often assume that the claim frequency \lfbox[conditions]{$N \sim \text{Pois}(\lambda_{N})$} and then apply the normal approximation to find the standard for full credibility for claim frequency \lfbox[formula]{$\lambda_{F}$}. First, we impose that the probability of the claim being with $k$ of the mean must be at least $1 - \alpha$. Then, we rewrite \lfbox[conditions]{$\frac{k \mu_{N}}{\sigma_{N}} = k\sqrt{\lambda_{N}}$} and set \lfbox[formula]{$\lambda_{N} \geq \left(\frac{z_{1 - \alpha/2}}{k}\right)^{2}$} where \lfbox[conditions]{$\lambda_{F} = \left(\frac{z_{1 - \alpha/2}}{k}\right)^{2}$}.


\subsubsection{Claim Severity}
We assume that the loss amounts $X_{1}, X_{2}, \dots, X_{N}$ are independent and identically distributed random variables with mean $\mu_{X}$ and variance $\sigma^{2}_{X}$. Full credibility is attributed to \lfbox[conditions]{$D = \bar{X}$} if \lfbox[conditions]{$2\Phi\left(\frac{k \mu_{X}}{\sigma_{N}/\sqrt{N}}\right) - 1 \geq 1 - \alpha$}. 

\bigskip

Similarly to claim frequency, we apply the normal approximation with \lfbox[conditions]{$\bar{X} \approx \mathcal{N}\left(\mu_{X}, \sigma^{2}_{X}/N\right)$}. Then, we find \lfbox[formula]{$N \geq \left(\frac{z_{1 - \alpha/2}}{k}\right)^{2} \cdot \left(\frac{\sigma_{X}}{\mu_{X}}\right)^{2} = \lambda_{F} CV_{X}^{2}$} where the \textbf{\textit{standard for full credibility for claim severity}} is $\lambda_{F}CV_{X}^{2}$.


\subsubsection{Aggregate Loss}
For the aggregate loss $S = X_{1} + X_{2} + \hdots + X_{N}$, we have \lfbox[formula]{$\mu_{S} = \mu_{N} \mu_{X}$} and \lfbox[formula]{$\sigma^{2}_{S} = \mu_{N} \sigma^{2}_{X} + \mu_{X}^{2} \sigma^{2}_{N}$}.

\bigskip

With the same normality assumptions for the Poisson distributed $N$, we find \lfbox[formula]{$\lambda_{N} \geq \left(\frac{z_{1 - \alpha/2}}{k}\right)^{2} \cdot \left(\frac{\mu_{X}^{2} + \sigma^{2}_{X}}{\mu_{X}^{2}}\right) = \lambda_{F} (1 + CV_{X}^{2})$} where the \textbf{\textit{standard for full credibility for claim severity}} is $\lambda_{F}(1 + CV_{X}^{2})$.

\paragraph{Note}	The conditions are the same for the \textit{\textbf{Pure Premium}} as for the aggregate loss.


%\columnbreak
\subsection{Partial Credibility}\label{subsec:PartialCred}
The \textbf{\textit{credibility factor}} for :
\begin{description}
	\item[Claim Frequency]	is \lfbox[formula]{$Z = \sqrt{\frac{\lambda_{N}}{\lambda_{F}}}$}.
	\item[Claim Severity]	is \lfbox[formula]{$Z = \sqrt{\frac{N}{\lambda_{F} CV_{X}^{2}}}$}.
	\item[Aggregate Loss and Pure Premium]	is \lfbox[formula]{$Z = \sqrt{\frac{\lambda_{N}}{\lambda_{F}(1 + CV_{X}^{2})}}$}
\end{description}


\newpage
\section{BÃ¼hlmann Credibility}\label{sec:Buhl}
\begin{rappel_enhanced}[Context]
Buhlmann's approach, a.k.a. the greatest accuracy approach or the least squares approach, estimates the future loss measure $X_{n }$
\end{rappel_enhanced}
\subsection{Basic framework}

 

\subsection{Variance components}



\subsection{Credibility factors}
%BÃ»hlmann and BÃ»hlmann-Straub factors
%Estimate loss



\newpage
\section{Bayesian Credibility}\label{sec:Bayes}
\subsection{Basic framework}


\subsection{Premium}



\subsection{Conjugate distributions}

\subsection{Nonparametric empirical Bayes method}




\newpage
\part{Linear Mixed Models}\label{part:LMM}




\newpage
\part{Bayesian Analysis and Markov Chain Monte Carlo}\label{part:BAandMCMC}




\newpage
\part{Statistical Learning}\label{part:statLearn}
\section{K-Nearest Neighbors}\label{sec:KNN}


\newpage
\section{Decision Trees}
%	building, purpose, pruning
%	bagging, random forests, boosting


\newpage
\section{Principal Components Analysis (PCA)}\label{sec:PCA}
%	purpose and computations
%	interpretation of software outputs	


\newpage
\section{Clustering}
%	purpose and computations
%	interpretation of software outputs





\end{multicols*}
\end{document}
