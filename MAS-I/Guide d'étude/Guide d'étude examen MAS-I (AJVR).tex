\documentclass[12pt, titlepage, french]{report}
\input{../../preambule.tex}
%% -----------------------------
%% Section Font customization
%% -----------------------------
\title{
	Guide d'étude	\\
	\large Examen MAS-I: Modern Actuarial Statistics I\\
	Casualty Actuarial Society (CAS)}
\vspace{-8ex}
\date{}
\author{Alec James van Rassel}

\begin{document}

\maketitle

\tableofcontents

\clearpage

\part*{Préliminaire}

\section{Information}

\begin{distributions}[Objectives]
\begin{itemize}
	\item	Set forth, usually in broad terms, what the candidate should be able to do in actual practice;
	\item	The objectives include methodologies that may be impossible to perform on an exam that the candidate is expected to be able to explain conceptually;
	\item	\textit{For example}: The Hat Matrix couldn't be calculated, but conceptual questions about it could be asked;
\end{itemize}
\end{distributions}

\begin{outcomes}[Learning outcomes]
\begin{enumerate}
	\item	It's important to identify some of the key terms, concepts, and methods associated with each of the learning objectives;
	\item	They aren't an exhaustive list of the material being tested, but rather illustrate the scope of each learning objective;
\end{enumerate}
\end{outcomes}

\begin{CHPT_SUMM}{Information additionnelle}
	\begin{itemize}
		\item	The learning objectives define the behaviours and the knowledge statements illustrate more fully their intended scope;
		\item	Learning objectives should not be seen as independent units but as building blocks for our understanding;
		\item	The ranges are just guidelines;
		\item	The overall section weights should be seen as having more significance than the individual section weights;
		\item	Tables include :
			\begin{itemize}
			\item	values for the illustrative life tables;
			\item	Standard normal distribution;
			\item	Abridiged inventories of discrete and continuous probability distributions;
			\item	Chi-square distribution;
			\item	$t$-distribution;
			\item	$F$-distribution;
			\end{itemize}
		\item	\textbf{There is a guessing adjustement};
	\end{itemize}
\end{CHPT_SUMM}

\part*{Sujets à l'étude}

\chapter[Probability models (Stochastic Processes and Survival Models)]{Probability models (Stochastic Processes and Survival Models) (20\% à 35\%)}

\subsection{Information}

\begin{distributions}[Description]
Notes du descriptif principal:
\begin{itemize}
	\item	Stochastic processes
	\item	Survival models
		\begin{itemize}
		\item	Covered in depth as part of probability modeling in generic terms;
		\end{itemize}
	\item	Markov Chains
		\begin{itemize}
		\item	Provide the means to model how an entity can move through different states;
		\end{itemize}
	\item	Simplified version of life contingencies
		\begin{itemize}
		\item	Life contingencies problems can be viewed as discounted cash flow problems which include thee effect of probability of payment;
		\item	Covered through a study note which link the generic survival model concepts to a subset of life actuarial concepts;
		\item	This study note illustrates how to calculate annuities or single premium insurance amounts;
		\end{itemize}
\end{itemize}
\tcbline
Notes de la sous-section:
\begin{itemize}
	\item	Résoudre des problèmes de processus aléatoires;
	\item	Identifier les probabilités et distributions associées avec ces processus;
		\begin{itemize}
		\item	Particulièrement, être capable d'utiliser un processus de Poisson dans ces applications;
		\end{itemize}
	\item	Les modèles de survie sont une rallonge aux modèles de probabilité de processus stochastiques;
		\begin{itemize}
		\item	En lieu, on estime la vie futur d'une entité avec quelques suppositions sur la distribution de la vraisemblance de survie;
		\end{itemize}
	\item	Chaines de Markov utiles pour modéliser la mobilité entre états dans un processus et souligner les modèles Bayésien MCMC sous-jacent;
	\item	La simulation est incluse puisqu'elle peut s'avérer essentielle pour arriver à une solution de problème complexe;
\end{itemize}
\end{distributions}


\begin{outcomes}[Learning objectives]
\begin{enumerate}
	\item	Understand and apply the properties of Poisson processes;
		\begin{itemize}
		\item	For increments in the homogeneous case;
		\item	For interval times in the homogeneous case;
		\item	For increments in the non-homogenous case;
		\item	Resulting from special types of events in the Poisson process;
		\item	Resulting from sums of independant Poisson processes;
		\end{itemize}
\tcbline
	\item	For any Poisson process and the inter-arrival and waiting distributions associated with the Poisson process, calculate:
		\begin{itemize}
		\item	Expected values;
		\item	Variances;
		\item	Probabilities;
		\end{itemize}
\tcbline
	\item	For a compound Poisson process, calculate moments associated with the value of the process at a given time;
\tcbline
	\item	Apply the Poisson process concepts to calculate the hazard function and related survival model concepts;
		\begin{itemize}
		\item	Relationship between hazard rate, probability density function and cumulative distribution function;
		\item	Effect of memoryless nature of Poisson distribution on survival time estimation;
		\end{itemize}
\tcbline
	\item	Given the joint distribution of more than one source of failure in a system (or life) and using Poisson Process assumptions:
		\begin{itemize}
		\item	Calculate probabilities and moments associated with functions of these random variables' variances;
		\item	Understand differences between a series system (joint life) and parallel system (last survivor) when calculating expected time to failure or probability of failure by a certain time;
		\item	Understand the effect of multiple sources of failure (multiple decrement) on expected system time to failure (expected lifetime);
		\end{itemize}
\tcbline
	\item	For discrete Markov Chains under both homogeneous and non-homogenous states:	
		\begin{itemize}
		\item	Definition of a Markov Chain;
		\item	Chapman-Kolmogorov Equations for $n$-step transition calculations;
		\item	Accessible states;
		\item	Ergodic Markov Chains and limiting probabilities;
		\end{itemize}
\tcbline
	\item	Solve Life Contingency problems using a life table in a spreadsheet as the combined result of discount, probability of payment and amount of payment vectors. Understand the linkage between the life table and the corresponding probability models;
		\begin{itemize}
		\item	Calculate annuities for discrete time;
		\item	Calculate life insurance single net premiums (or P \& C pure premiums) for discrete time;
		\item	Solve for net level premiums (\textbf{not} including fractional lives);
		\end{itemize}
\tcbline
	\item	The candidate should be familiar with basic computer simulation methods.
		\begin{itemize}
		\item	Understand the basic framework of Monte Carlo Simulation;
		\item	Understand the mechanics of generating uniform random numbers;
		\item	Generate random numbers from a variety of distributions using the inversion method;
		\item	Be able to explain when and how to use the Acceptance-Rejection method;
		\end{itemize}
\end{enumerate}
\end{outcomes}

\begin{ASM_chapter}[Related lessons ASM]
\begin{enumerate}
	\item	\nameref{L.-1}
	\item	\nameref{L.-2}
	\item	\nameref{L.-3}
\tcbline
	\item	\nameref{L.-4}
	\item	\nameref{L.-5}
	\item	\nameref{L.-6}
	\item	\nameref{L.-7}
	\item	\nameref{L.-8}
	\item	\nameref{L.-9}
	\item	\nameref{L.-10}
	\item	\nameref{L.-11}
	\item	\nameref{L.-12}
	\item	\nameref{L.-13}
	\item	\nameref{L.-14}
	\item	\nameref{L.-15}
	\item	\nameref{L.-16}
	\item	\nameref{L.-17}
	\item	\nameref{L.-18}
	\item	\nameref{L.-19}
\tcbline
	\item	\nameref{L.-20}
	\item	\nameref{L.-21}
\tcbline
	\item	\nameref{L.-22}
	\item	\nameref{L.-23}
	\item	\nameref{L.-24}
\end{enumerate}
\end{ASM_chapter}

\begin{YTB_vids}[Vidéos YouTube]
\begin{itemize}
	\item	
\end{itemize}
\end{YTB_vids}

\subsection{Résumés des chapitres}

\subsubsection*{Probability Review}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-1}]{Probability Review}
Introduction to Mathematical Statistics 1 - 3, 5
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-2}]{Parametric Distributions}
Introduction to Mathematical Statistics 2.2, 2.7
Nonlife Actuarial Models---Theory Methods and Evaluation 2.2
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-3}]{Mixtures}
Introduction to Mathematical Statistics 3.7
Nonlife Actuarial Models---Theory Methods and Evaluation 2.3.2
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\subsubsection*{Stochastic Processes}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-4}]{Markov Chains: Chapman-Kolmogorov Equations}
Ross 4.1 - 4.2, 4.5.1 - 4.5.2
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-5}]{Markov Chains: Classification of States}
Ross 4.3
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-6}]{Discrete Markov Chains: Long-Run Proportions and Limiting Probabilities}
Ross 4.4
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-7}]{Markov Chains: Time in Transient States}
Ross 4.6
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-8}]{Markov Chains: Branching Processes}
Ross 4.7
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-9}]{Markov Chains: Time Reversible}
Ross 4.8
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-10}]{Exponential Distribution}
Ross 5.2
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-11}]{The Poisson Process: Probabilities of Events}
Ross 5.3.1 - 5.3.2
Daniel Poisson Study Note 1.1, 1.4.1
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-12}]{The Poisson Process: Time To Next Event}
Ross 5.2, 5.3.3
Daniel Poisson Study Note 1.1.1
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-13}]{{The Poisson Process: Thinning, or Couting Special Types of Events}}
Ross 5.3.4
Daniel Poisson Study Note 1.3.1, 1.4.3
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-14}]{The Poisson Process: Other Characteristics}
Ross 5.2.3, 5.3.4, 5.3.5
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-15}]{The Poisson Process: Sums and Mixtures}
Ross 5.4.3
Daniel Poisson Study Note 1.3.2, 1.3.3
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-16}]{Compound Poisson Processes}
Ross 5.4.2
Daniel Poisson Study Note 1.2, 1.4.2
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-17}]{Reliability: Structure Functions}
Ross 9.1 - 9.2
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-18}]{Reliability: Probabilities}
Ross 9.3 - 9.4
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-19}]{Reliability: Time to Failure}
Ross 9.5 - 9.6
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\subsubsection*{Life Contingencies}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-20}]{Survival Models}
Struppeck 1, 2, 6, 7
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-21}]{Contingent Payments}
Struppeck 3, 4, 5, 6
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\subsubsection*{Simulation}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-22}]{Simulation---Inverse Transformation Method}
Ross 11.1, 11.2.1
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-23}]{Simulation---Applications}
Ross 11.1, 11.2.1
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-24}]{Simulation---Rejection Method}
Ross 11.2.2
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\subsection{Notes sur les vidéos YouTube}

\begin{YTB_SUMM}[label = {SQ-BASICS-ML-INTRO}]{\href{https://www.youtube.com/watch?v=Gv9_4yMHFhI&list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&index=2&t=0s}{StatQuest: A Gentle Introduction to Machine Learning}}
\begin{itemize}
	\item	
\end{itemize}
\end{YTB_SUMM}

\newpage

\chapter[Statistics]{Statistics (15\% à 30\%)}

\subsection{Information}

\begin{distributions}[Description]
Notes du descriptif principal:
\begin{itemize}
	\item	Topics which would commonly be covered in a 2-semester Probability \& Statistics sequence;
\end{itemize}
\end{distributions}

\begin{outcomes}[Learning objectives]
\begin{enumerate}
	\item	Perform point estimation of statistical parameters using Maximum likelihood estimation (MLE). Apply criteria to estimates such as :
	\begin{multicols*}{2}
		\begin{itemize}
		\item	Consistency;
		\item	Unbiasedness;
		\item	Sufficiency;
		\item	Efficiency;
		\item	Minimum variance;
		\item	MSE;
		\end{itemize}
	\end{multicols*}
\tcbline
	Calculate parameter estimates using methods other than maximum likelihood;
	\item	Test statistical hypotheses including Type I and Type II errors using:
		\begin{itemize}
		\item	Neyman-Pearson theorem;
		\item[]	Apply Neyman-Pearson theorem to construct likelihood ratio equation;
		\item	Likelihood ratio tests;
		\item	First principles;
		\item[]	Use critical values from a sampling distribution to test means and variances;
		\end{itemize}
\tcbline
	\item	For the Exponential, Gamma, Weibull, Pareto, Lognormal, Beta, and mixtures thereof:
		\begin{itemize}
		\item	Identify the applciations to Insurance claim modeling in which each distribution is used and reasons why;
		\item	Transformation of distributions; 
		\end{itemize}
	\item	Calculate Order Statistics of a sample for a given distribution;
\end{enumerate}
\end{outcomes}

\begin{outcomes}[Knowledge Statements]
\begin{enumerate}[label = \alph*.]
	\item	Equations for MLE of mean, variance from a sample;
	\item	Estimation of mean and variance based on samples;
	\item	General equations for MLE of parameters;
	\item	Recognition of consistency property of estimators and alternative measures of consistency;
	\item	Application of criteria for measurement when estimating parameters through minimisation of variance, MSE;
	\item	Definition of statistical bias and recognition of estimators that are unbiased or biased;
	\item	Application of Rao-Cramer Lower Bound and Efficiency;
	\item	Relationship between Sufficiency and Minimum Variance;
	\item	Develop and estimate a sufficient statistic for a distribution;
	\item	Factorization Criterion for sufficiency;
	\item	Application of Rao-Cramer Lower Bound and Fisher Information;
	\item	Application of MVUE for the exponential class of distributions;
	\item	Linkage between Score Function, Fisher Information and maximum likelihood;
	\item	Method of Moments;
	\item	Percentile Matching;
	\item	Kernel Density Estimation;
	\item	Maximum Likelihood with Censoring and Truncation;
\end{enumerate}
\tcbline
\begin{enumerate}[label = \alph*.]
	\item	Presentation of fundamental inequalities based on general assumptions and normal assumptions;
	\item	Definition of Type I and Type II errors;
	\item	Significance levels;
	\item	One-sided versus two-sided tests;
	\item	Estimation of sample sizes under normality to control for Type I and Type II errors;
	\item	Determination of critical regions;
	\item	Definition and measurement of likelihood ratio tests;
	\item	Determining parameters and testing using tabular values (from a table);
	\item	Recognizing when to apply likelihood ratio tests versus chi-square or other goodness of fit tests;
	\item	Apply paired $t$-test to two samples;
	\item	Test for difference in variance under Normal distribution between two samples through the application of $F$-test;
	\item	Test of significance of means from two samples under Normal distribution assumptions in both large and small sample cases;
	\item	Test for significance of difference in proportions between two samples under the Binomial distribution assumption in both large and small sample cases;
	\item	Application of contingency tables to test independence between effects;
	\item	Asymptotic relationship between likelihood ratio tests and the Chi-Square distribution;
	\item	Application of Neyman-Pearson theorem to Uniformly Most Powerful hypothesis tests;
	\item	Equivalence between critical regions and confidence intervals;
	\item	Kolmogorov-Smirnov test;
\end{enumerate}
\tcbline
\begin{enumerate}[label = \alph*.]
	\item	Frequency, severity and aggregate loss;
	\item	Common continuous distributions for modeling claim severity;
	\item	Mixing distributions;
	\item	Tail properties of claim severity;
	\item	Effects of coverage modifications including, for example: limits, deductibles, loss elimination ratios and effects of inflation;
\end{enumerate}
\tcbline
\begin{enumerate}[label = \alph*.]
	\item	General form for distribution of $n^{\text{th}}$ largest element of a set;
	\item	Application to a given distributional form;
\end{enumerate}
\end{outcomes}

\begin{ASM_chapter}[Related lessons ASM]
\begin{enumerate}
  \setcounter{enumi}{24}
	\item	\nameref{L.-25}
	\item	\nameref{L.-26}
	\item	\nameref{L.-27}
	\item	\nameref{L.-28}
	\item	\nameref{L.-29}
	\item	\nameref{L.-30}
	\item	\nameref{L.-31}
	\item	\nameref{L.-32}
	\item	\nameref{L.-33}
	\item	\nameref{L.-34}
	\item	\nameref{L.-35}
	\item	\nameref{L.-36}
	\item	\nameref{L.-37}
	\item	\nameref{L.-38}
	\item	\nameref{L.-39}
	\item	\nameref{L.-40}
	\item	\nameref{L.-41}
\end{enumerate}
\end{ASM_chapter}

\begin{YTB_vids}[Vidéos YouTube]
\begin{itemize}
	\item	
\end{itemize}
\end{YTB_vids}

\begin{distributions}[Likely Questions]
\begin{itemize}
	\item	Question where we calculate the sample variance with the STAT function of the calculator;
		\begin{itemize}
		\item	MAS-I F19, \# 15	;
		\end{itemize}
\end{itemize}
\end{distributions}

\subsection{Résumés des chapitres}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-25}]{Estimator Quality}
Introduction to Mathematical  4.1.3, 5.1, 7.1
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-26}]{Kernel Density Estimation}
Nonlife Actuarial Models: Theory Methods and Evaluation 11.1
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-27}]{Method of Moments}
Nonlife Actuarial Models: Theory Methods and Evaluation 12.1.1
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-28}]{Percentile Matching}
Nonlife Actuarial Models: Theory Methods and Evaluation 11.1.1, 12.1.2
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-29}]{Maximum Likelihood Estimators}
Introduction to Mathematical Statistics 4.1, 6.1
Nonlife Actuarial Models: Theory Methods and Evaluation 10.2, 12.3
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-30}]{Maximum Likelihood Estimators---Special Techniques}
Introduction to Mathematical Statistics 4.1, 6.1
Nonlife Actuarial Models: Theory Methods and Evaluation 10.2, 12.3
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-31}]{Variance of Maximum Likelihood Estimator}
Introduction to Mathematical Statistics 6.2, 6.5
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-32}]{Sufficient Statistics}
Introduction to Mathematical Statistics 7
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-33}]{Hypothesis Testing}
Introduction to Mathematical Statistics 4.5, 4.6
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-34}]{Confidence Intervals and Sample Size}
Introduction to Mathematical Statistics 4.5, 4.6
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-35}]{Confidence Intervals for Means}
Introduction to Mathematical Statistics 4.2
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-36}]{Kolmogorov-Smirnov Tests}
Nonlife Actuarial Models: Theory Methods and Evaluation 13.2.1
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-37}]{Chi Square Tests}
Introduction to Mathematical 4.7
Nonlife Actuarial Models: Theory Methods and Evaluation 13.2.3
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-38}]{Confidence Intervals for Variances}
Introduction to Mathematical Statistics 8.3
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-39}]{Uniformly Most Powerful Critical Regions}
Introduction to Mathematical Statistics 8.1 - 8.2
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-40}]{Likelihood Ratio Tests}
Introduction to Mathematical Statistics 8.3
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-41}]{Q.-Q. Plots}
Introduction to Mathematical Statistics 4.4
Larsen Study Note
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\subsection{Notes sur les vidéos YouTube}

\begin{YTB_SUMM}[label = {SQ-BASICS-ML-INTRO}]{\href{https://www.youtube.com/watch?v=Gv9_4yMHFhI&list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&index=2&t=0s}{StatQuest: A Gentle Introduction to Machine Learning}}
\begin{itemize}
	\item	
\end{itemize}
\end{YTB_SUMM}

\newpage

\chapter[Extended Linear Models]{Extended Linear Models (30\% à 50\%)}

\subsection{Information}

\begin{distributions}[Description]
Notes du descriptif principal:
\begin{itemize}
	\item	Include GLMs which are commonly used to construct classification plans;
	\item	OLS model is covered as one member of the exponential family;
	\item	\texttt{R} is useful to better visualise and conceptualise the material;
\end{itemize}
\tcbline
Notes de la sous-section:
\begin{itemize}
	\item	OLS treated as \textit{one} type of model that may be used when the dependant variable follows the Normal distribution and the observations are (iid) with a constant variance;
	\item	All models assume data is (iid) from the exponentional family;
	\item	Assume linear relationship between dependant and independant variables;
	\item	Assume variance is a function of the mean;
	\item	\textbf{VIF} formula found on p. 102 of James et al. and p. 101 of Dobson is used and not hte one on p. 101 of James and et al.;
		\begin{align*}
			\text{VIF}(b_{j})
			&=	\frac{1}{1 - R_{(j)}^{2}}
		\end{align*}
	\item	Questions may contain parameter tables and plots (of the type shown in texts) with which we should familiarise ourselves;
\end{itemize}
\end{distributions}

\begin{outcomes}[Learning objectives]
\begin{enumerate}
	\item	Understand the assumptions behind different forms of the Extended Linear Model and be able to select the appropriate model from list below:
	\begin{multicols*}{2}
		\begin{itemize}
		\item	OLS;
		\item	GLM;
		\item	ANOVA;
		\item	GAM;
		\item	Local Regression;
		\item	Lasso;
		\item	Ridge Regression;
		\item	Partial Least Squares;
		\item	PCA regression;
		\end{itemize}
	\end{multicols*}
\tcbline
	\item	Evaluate models developed using Extended Linear Model approach;
\tcbline
	\item	Understand the algorithms behind the numerical solutions for the different forms of the Extended Linear Model family to enable interpretation of output from the statistical software employed in modeling and to make appropriate modeling choices when selecting modeling options;
\tcbline
	\item	Understand and be able to select the appropriate model structure for an Extended Linear Model given the behavior of the data set to be modeled;
\tcbline
	\item	
\tcbline
\end{enumerate}
\end{outcomes}

\begin{ASM_chapter}[Related lessons ASM]
\begin{enumerate}
  \setcounter{enumi}{41}
	\item	\nameref{L.-42}
	\item	\nameref{L.-43}
	\item	\nameref{L.-44}
	\item	\nameref{L.-45}
	\item	\nameref{L.-46}
	\item	\nameref{L.-47}
	\item	\nameref{L.-48}
	\item	\nameref{L.-49}
	\item	\nameref{L.-50}
	\item	\nameref{L.-51}
	\item	\nameref{L.-52}
	\item	\nameref{L.-53}
	\item	\nameref{L.-54}
	\item	\nameref{L.-55}
	\item	\nameref{L.-56}
\end{enumerate}
\end{ASM_chapter}

\begin{YTB_vids}[Vidéos YouTube]
\begin{itemize}
	\item	
\end{itemize}
\end{YTB_vids}

\subsection{Résumés des chapitres}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-42}]{Introduction to Extended Linear Models}
Introduction to Mathematical Statistics 4.4
Introduction to Generalized Linear Models 2
Introduction to Statistical Learning with R 2 (except 2.2.3)
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-43}]{How a Generalized Linear Model Works}
Introduction to Generalized Linear Models 3.9
Introduction to Statistical Learning with R 3.3.1 - 3.3.2
Larsen Study Note
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-44}]{How a Generalized Linear Model Works: Categorical Response}
Introduction to Generalized Linear Models 7, 8
Introduction to Statistical Learning with R 4
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-45}]{Generalized Linear Model: Estimating Parameters}
Introduction to Generalized Linear Models 4
Introduction to Statistical Learning with R 3.1.1, 3.2.1
Larsen Study Note
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-46}]{Generalized Linear Model: Measures of Fit}
Introduction to Generalized Linear Models 5
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-47}]{{Normal Linear Model: Standard Error, $R$-squared, and $t$-statistic}}
Introduction to Generalized Linear Models 6.1 - 6.3
Introduction to Statistical Learning with R 3.1.2 - 3.1.3, 3.2.2 - 3.2.3
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-48}]{Normal Linear Model: $F$ and VIF}
Introduction to Generalized Linear Models 6.2
Introduction to Statistical Learning with R 3
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-49}]{Normal Linear Model: Validation}
Introduction to Generalized Linear Models 6.2
Introduction to Statistical Learning with R 3.3.3
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-50}]{Normal Linear Model: Predictions}
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-51}]{ANOVA}
Introduction to Generalized Linear Models 6.4 - 6.5, 9.3 - 9.7
Introduction to Mathematical Statistics 9.1 - 9.5
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-52}]{Generalized Linear Model: Measures of Fit II}
Introduction to Generalized Linear Models 7, 8, 9
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-53}]{Resampling Methods}
Introduction to Statistical Learning with R 5
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-54}]{Normal Linear Model: Subset Selection}
Introduction to Statistical Learning with R 6.1
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-55}]{Normal Linear Model: Shrinkage and Dimension Reduction}
Introduction to Statistical Learning with R 6.2 - 6.4
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\begin{CHPT_SUMM_AUTO_NUMB}[label = {L.-56}]{Extensions to the Linear Model}
Introduction to Statistical Learning with R 7
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO_NUMB}

\subsection{Notes sur les vidéos YouTube}

\begin{YTB_SUMM}[label = {SQ-BASICS-ML-INTRO}]{\href{https://www.youtube.com/watch?v=Gv9_4yMHFhI&list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&index=2&t=0s}{StatQuest: A Gentle Introduction to Machine Learning}}
\begin{itemize}
	\item	
\end{itemize}
\end{YTB_SUMM}

\newpage

\chapter[Time Series with Constant Variance]{Time Series with Constant Variance (10\% à 20\%)}

\subsection{Information}

\begin{distributions}[Description]
Notes du descriptif principal:
\begin{itemize}
	\item	Covers an introduction to modeling activity, such as financial results or stock prices, over time;
	\item	The model used is the Auto Regressive Integrated Moving Average (ARIMA) where activity in a given period may be linked to activity in subsequent time periods;
	\item	The connection between adjacent time periods violates one of the assumptions behind the Extended Linear Model techniques;
	\item	The ARIMA appproach incorporates that linkage as an aid for it's predictions;
	\item	Also covers the application of regression models to time series analysis;
\end{itemize}
\tcbline
Notes de la sous-section:
\begin{itemize}
	\item	Section covers basic applications of the ARIMA time series model;
\end{itemize}
\end{distributions}

\begin{outcomes}[Learning objectives]
\begin{enumerate}
	\item	Use time series to model trends;
		\begin{itemize}
		\item	Estimation, data analysis, and forecasting;
		\item	Forecast errors and confidence intervals;
		\end{itemize}
\tcbline
	\item	Model relationships of current and past values of a statistic / metric;
		\begin{itemize}
		\item	Estimation, data analysis, and forecasting;
		\item	Forecast errors and confidence intervals;
		\end{itemize}
\tcbline
	\item	Understand forecasts produced by ARIMA;
\tcbline
	\item	Time Series with Regression;
\end{enumerate}
\end{outcomes}

\begin{ASM_chapter}[Related lessons ASM]
\begin{itemize}
	\item[]	\nameref{L.-57}
	\item[]	\nameref{L.-58}
	\item[]	\nameref{L.-59}
	\item[]	\nameref{L.-60}
	\item[]	\nameref{L.-61}
	\item[]	\nameref{L.-62}
	\item[]	\nameref{L.-63}
	\item[]	\nameref{L.-64}
\end{itemize}
\end{ASM_chapter}

\begin{YTB_vids}[Vidéos YouTube]
\begin{itemize}
	\item	
\end{itemize}
\end{YTB_vids}

\subsection{Résumés des chapitres}

\begin{CHPT_SUMM_AUTO}[label = {L.-57}]{57. Time Series: Trend and Seasonality}
Introduction to Time Series with \texttt{R} 1
\begin{itemize}
	\item[1:]	Time Series Data
\end{itemize}
\tcbline
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO}

\begin{CHPT_SUMM_AUTO}[label = {L.-58}]{58. Time Series: Correlation}
Introduction to Time Series with \texttt{R} 2 - 3.1
\begin{itemize}
	\item[2:]	Correlation
	\item[3.1:]	Forecasting Strategies---Purpose
\end{itemize}
\tcbline
	\begin{enumerate}
		\item	Second order properties of a time series;
		\item	Relationships of different time series;
	\end{enumerate}
\end{CHPT_SUMM_AUTO}

\begin{CHPT_SUMM_AUTO}[label = {L.-59}]{59. Time Series: White Noise and Random Walks}
Introduction to Time Series with \texttt{R} 4.1 - 4.4
\begin{itemize}
	\item[4.1:]	Basic Stochastic Models---Purpose
	\item[4.2:]	Basic Stochastic Models---White Noise
	\item[4.3:]	Basic Stochastic Models---Random Walks
	\item[4.4:]	Basic Stochastic Models---Fitted models and diagnostic plots
\end{itemize}
\tcbline
	\begin{enumerate}
		\item	White noise;
		\item	Random walks;
	\end{enumerate}
\end{CHPT_SUMM_AUTO}

\begin{CHPT_SUMM_AUTO}[label = {L.-60}]{60. Time Series: Autoregressive Models}
Introduction to Time Series with \texttt{R} 4.5 - 4.8
\begin{itemize}
	\item[4.5:]	Basic Stochastic Models---AR models
	\item[4.6:]	Basic Stochastic Models---Fitted models
	\item[4.7:]	Basic Stochastic Models---Summary of \texttt{R} commands
	\item[4.8:]	Basic Stochastic Models---Exercices
\end{itemize}
\tcbline
	\begin{enumerate}
		\item[]	Correlograms and partial correlograms;
		\item[]	Stationnarity;
		\item[]	Forecasting with $AP(p)$ series;
	\end{enumerate}
\end{CHPT_SUMM_AUTO}

\begin{CHPT_SUMM_AUTO}[label = {L.-61}]{61. Time Series: Regression}
Introduction to Time Series with \texttt{R} 5
\begin{itemize}
	\item[5:]	Regression
\end{itemize}
\tcbline
	\begin{enumerate}
		\item	Correcting for autocorrelation;
		\item	Seasonality;
		\item	Logarithmic transformations;
		\item	Error correction factors;
	\end{enumerate}
\end{CHPT_SUMM_AUTO}

\begin{CHPT_SUMM_AUTO}[label = {L.-62}]{62. Time Series: Moving Average Models}
Introduction to Time Series with \texttt{R} 6.1 - 6.4
\begin{itemize}
	\item[6.1:]	Stationary Models---Purpose
	\item[6.2:]	Stationary Models---Strictly stationary series
	\item[6.3:]	Stationary Models---MA models
	\item[6.4:]	Stationary Models---Fitted MA models
\end{itemize}
\tcbline
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO}

\begin{CHPT_SUMM_AUTO}[label = {L.-63}]{63. Time Series: ARMA Models}
Introduction to Time Series with \texttt{R} 6.5 - 6.8
\begin{itemize}
	\item[6.5:]	Stationary Models---Mixed models: The ARMA process
	\item[6.6:]	Stationary Models---ARMA models: Empirical Analysis
	\item[6.7:]	Stationary Models---Summary of \texttt{R} commands
	\item[6.8:]	Stationary Models---Exercices
\end{itemize}
\tcbline
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO}

\begin{CHPT_SUMM_AUTO}[label = {L.-64}]{64. Time Series: ARIMA and SARIMA Models}
Introduction to Time Series with \texttt{R} 7.1 - 7.3
\begin{itemize}
	\item[7.1:]	Non-stationary Models---Purpose
	\item[7.2:]	Non-stationary Models---Non-Seasonal ARIMA models
	\item[7.3:]	Non-stationary Models---Seasonal ARIMA models
\end{itemize}
\tcbline
	\begin{itemize}
		\item	
	\end{itemize}
\end{CHPT_SUMM_AUTO}

\subsection{Notes sur les vidéos YouTube}

\begin{YTB_SUMM}[label = {SQ-BASICS-ML-INTRO}]{\href{https://www.youtube.com/watch?v=Gv9_4yMHFhI&list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&index=2&t=0s}{StatQuest: A Gentle Introduction to Machine Learning}}
\begin{itemize}
	\item	
\end{itemize}
\end{YTB_SUMM}

\newpage

\end{document}
